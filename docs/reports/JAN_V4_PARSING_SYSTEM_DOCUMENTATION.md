# Jan v4.0 Parsing Evaluation + Improvement System

## Executive Summary

The Jan v4.0 parsing system represents a comprehensive architecture upgrade implementing strategic recommendations to achieve **80%+ overall pass rate** while preserving existing strengths and fixing critical performance bottlenecks. The system transitions from simple rule-based extraction to a sophisticated multi-engine architecture with deterministic evaluation capabilities.

### Key Achievements

- **ðŸŽ¯ Target Performance**: 80%+ overall pass rate (up from ~50%)
- **ðŸ”§ Multi-Engine Architecture**: 6-layer urgency detection, multi-pass amount extraction, cross-field coordination, fragment processing
- **ðŸ“Š Enhanced Evaluation**: Real/simulation modes, weighted scoring, difficulty breakdown, comprehensive reporting  
- **ðŸš€ Production Ready**: Deterministic evaluation, no OpenAI dependencies, stable fallback mechanisms
- **âš¡ Performance Focused**: Addresses PRIMARY (urgency ~50% â†’ 80%+) and SECONDARY (amount ~50% â†’ 80%+) bottlenecks

### Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Jan v4.0 System                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Evaluation Runner (run_parsing_eval.ts)                   â”‚
â”‚  â”œâ”€â”€ Real/Simulation Mode Toggle                           â”‚
â”‚  â”œâ”€â”€ Dataset: transcripts_golden_v4_core30.jsonl           â”‚
â”‚  â””â”€â”€ Weighted/Binary Scoring with 0.85 threshold           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Core Parsing Engines                                      â”‚
â”‚  â”œâ”€â”€ UrgencyAssessmentEngine (6-layer detection)           â”‚
â”‚  â”œâ”€â”€ AmountDetectionEngine (multi-pass extraction)         â”‚
â”‚  â”œâ”€â”€ MultiFieldCoordinationEngine (cross-validation)       â”‚
â”‚  â””â”€â”€ FragmentProcessor (speech cleaning)                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Integration Layer                                          â”‚
â”‚  â”œâ”€â”€ rulesEngine.ts (existing integration points)          â”‚
â”‚  â””â”€â”€ parsingAdapter.ts (simulation fallback)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## System Components

### 1. Core Parsing Engines

#### UrgencyAssessmentEngine (`urgencyEngine.ts`)
**Purpose**: Address PRIMARY performance blocker (urgency assessment 50% â†’ 80%+ accuracy)

**Architecture**: 6-layer detection system with weighted aggregation
- **Layer 1**: Explicit urgency markers (`urgent`, `emergency`, `critical`)
- **Layer 2**: Contextual urgency indicators (deadlines, constraints, consequences)
- **Layer 3**: Temporal urgency (time-bound expressions, immediacy)
- **Layer 4**: Emotional urgency (desperation, fear, panic markers)
- **Layer 5**: Consequence urgency (severity of outcomes)
- **Layer 6**: Safety urgency (danger, violence, threat indicators)

**Key Features**:
- Weighted aggregation with context modifiers
- Confidence scoring with calibration
- Support for complex multi-factor urgency scenarios
- Robust handling of implicit urgency cues

**Integration**: 
```typescript
// Replaces extractUrgency functions in rulesEngine.ts
import { UrgencyAssessmentEngine } from './urgencyEngine';
const urgencyEngine = new UrgencyAssessmentEngine();
const result = await urgencyEngine.assessUrgency(transcriptText);
```

#### AmountDetectionEngine (`amountEngine.ts`)  
**Purpose**: Address SECONDARY performance blocker (amount detection 50% â†’ 80%+ accuracy)

**Architecture**: Multi-pass detection system with vague expression support
- **Pass 1**: Explicit amount extraction (direct dollar figures)
- **Pass 2**: Contextual amount calculation (rent Ã— months, etc.)
- **Pass 3**: Vague amount mapping (`couple hundred`, `few thousand`)
- **Pass 4**: Ambiguity rejection (wages, ages, dates, phone numbers)
- **Pass 5**: Cross-validation and confidence scoring

**Key Features**:
- Comprehensive vague expression dictionary
- Smart contextual calculation (deposits + rent, etc.)
- Robust ambiguity filtering 
- Range handling (`between $X and $Y`)
- Written number support (`fifteen hundred`)

**Integration**:
```typescript
// Replaces extractGoalAmount functions in rulesEngine.ts
import { AmountDetectionEngine } from './amountEngine';
const amountEngine = new AmountDetectionEngine();
const result = await amountEngine.detectAmount(transcriptText);
```

#### MultiFieldCoordinationEngine (`coordinationEngine.ts`)
**Purpose**: Prevent cascading failures through cross-field validation

**Architecture**: 3-component coordination system
- **CrossFieldValidator**: Consistency checking between fields
- **ConfidenceCalibrator**: Dynamic confidence adjustment based on field agreement
- **FieldEnhancer**: Context-driven field enhancement using cross-field information

**Key Features**:
- Category-amount consistency validation (medical costs vs amounts)
- Urgency-temporal coordination (deadlines with urgency levels)  
- Name extraction coordination (avoiding category/urgency words as names)
- Dynamic confidence recalibration based on field agreement

**Integration**:
```typescript
// Enhances all extraction results in rulesEngine.ts
import { MultiFieldCoordinationEngine } from './coordinationEngine';
const coordinator = new MultiFieldCoordinationEngine();
const enhanced = await coordinator.coordinateFields(extractionResults);
```

#### FragmentProcessor (`fragmentProcessor.ts`)
**Purpose**: Handle incomplete speech and filler words affecting extraction

**Architecture**: 3-component processing pipeline
- **FillerWordProcessor**: Remove uh/um/er/ah, emotional artifacts, stuttering
- **FragmentReconstructor**: Handle incomplete sentences, hanging conjunctions
- **IncompletenessAssessor**: Measure speech fragmentation (0.0-1.0 score)

**Key Features**:
- Comprehensive filler word removal (50+ patterns)
- Intelligent sentence reconstruction
- Fragment quality scoring
- Preservation of semantic meaning during cleanup

**Integration**:
```typescript
// Preprocesses transcripts before extraction in rulesEngine.ts
import { FragmentProcessor } from './fragmentProcessor';
const processor = new FragmentProcessor();
const cleaned = await processor.processForExtraction(transcriptText);
```

### 2. Enhanced Evaluation Framework

#### Canonical Evaluation Runner (`run_parsing_eval.ts`)
**Features**:
- **Real/Simulation Toggle**: `EVAL_MODE=real|simulation`
- **Dataset Configuration**: `EVAL_DATASET=transcripts_golden_v4_core30`
- **Scoring Modes**: `EVAL_SCORING=binary|weighted` with 0.85 threshold
- **Comprehensive Reporting**: Pass rates, field accuracy, confidence analysis, difficulty breakdown

#### v4.0 Core Dataset (`transcripts_golden_v4_core30.jsonl`)
**Structure**: 30 balanced test cases targeting specific parsing challenges
- **10 Urgency-Heavy Cases**: Complex temporal, safety, and emotional urgency scenarios
- **10 Amount-Heavy Cases**: Vague expressions, contextual calculations, ambiguity rejection
- **5 Multi-Category Conflicts**: Cross-field coordination challenges
- **5 Fragment/Noisy Speech**: Filler words, stuttering, emotional artifacts

**Difficulty Distribution**:
- **Easy**: 8 cases (baseline functionality)
- **Medium**: 12 cases (standard complexity)  
- **Hard**: 7 cases (complex multi-factor scenarios)
- **Adversarial**: 3 cases (edge cases, potential false positives)

### 3. Integration Architecture

#### Enhanced Rules Engine Integration
All new engines are seamlessly integrated into existing `rulesEngine.ts`:

```typescript
// Import all Jan v4.0 engines
import { UrgencyAssessmentEngine } from './urgencyEngine';
import { AmountDetectionEngine } from './amountEngine';
import { MultiFieldCoordinationEngine } from './coordinationEngine';
import { FragmentProcessor } from './fragmentProcessor';

// Engine instances (initialized once)
const urgencyEngine = new UrgencyAssessmentEngine();
const amountEngine = new AmountDetectionEngine();
const coordinator = new MultiFieldCoordinationEngine();
const fragmentProcessor = new FragmentProcessor();

// Integration points replace existing functions:
// extractUrgency* â†’ urgencyEngine.assessUrgency()
// extractGoalAmount* â†’ amountEngine.detectAmount()
// All results â†’ coordinator.coordinateFields()
```

#### Production Deployment Adapter (`parsingAdapter.ts`)
**Enhanced Features**:
- **Stable Fallback Simulation**: Deterministic results when real services unavailable
- **Mode Detection**: Automatic real vs simulation mode switching
- **Error Handling**: Graceful degradation with logging
- **Performance Monitoring**: Execution time and confidence tracking

## Usage Instructions

### Running Evaluations

#### Basic Evaluation (Default Settings)
```bash
# Uses transcripts_golden_v4_core30.jsonl in real mode with weighted scoring
cd backend/eval/runners
node run_parsing_eval.js
```

#### Configuration Options
```bash
# Simulation mode (no real service dependencies)
EVAL_MODE=simulation node run_parsing_eval.js

# Binary scoring mode
EVAL_SCORING=binary node run_parsing_eval.js

# Custom dataset
EVAL_DATASET=transcripts_golden_v3 node run_parsing_eval.js

# Combined configuration
EVAL_MODE=simulation EVAL_SCORING=binary EVAL_DATASET=transcripts_golden_v4_core30 node run_parsing_eval.js
```

#### Output Files
Evaluation generates comprehensive reports in `backend/eval/outputs/`:
- `eval-results-YYYY-MM-DD.json`: Detailed JSON results
- `eval-errors-YYYY-MM-DD.jsonl`: Failed cases analysis
- `eval-summary-YYYY-MM-DD.md`: Human-readable summary report
- `eval-trace-YYYY-MM-DD.jsonl`: Debug traces (if enabled)

### Development Integration

#### Adding New Test Cases
1. Add entries to `transcripts_golden_v4_core30.jsonl`:
```json
{
  "id": "v4_031_new_test_case",
  "description": "Description of test scenario",
  "difficulty": "medium",
  "transcriptText": "Test transcript content...",
  "segments": [...],
  "expected": {
    "name": "Expected Name",
    "category": "EXPECTED_CATEGORY", 
    "urgencyLevel": "MEDIUM",
    "goalAmount": 1000
  }
}
```

#### Engine Configuration
Engines support configuration through constructor options:
```typescript
// Urgency engine with custom weights
const urgencyEngine = new UrgencyAssessmentEngine({
  layerWeights: {
    explicit: 0.25,
    contextual: 0.20,
    temporal: 0.20,
    emotional: 0.15,
    consequence: 0.15,
    safety: 0.05
  }
});

// Amount engine with custom vague mappings
const amountEngine = new AmountDetectionEngine({
  vagueExpressions: {
    "few dollars": 50,
    "some money": 100
    // ... custom mappings
  }
});
```

### Production Deployment

#### Environment Configuration
```bash
# Disable OpenAI calls for deterministic behavior
export ZERO_OPENAI_MODE=true

# Enable evaluation mode for stable parsing
export EVAL_MODE=simulation

# Configure logging levels
export LOG_LEVEL=info
```

#### Performance Monitoring
Monitor key metrics:
- **Overall Pass Rate**: Target 85%+ (weighted scoring)
- **Field Accuracy**: Name â‰¥90%, Category â‰¥90%, Urgency â‰¥80%, Amount â‰¥80%
- **Confidence Scores**: Average >0.75 across all fields
- **Execution Time**: <2s per transcript for production workloads

#### Fallback Strategy
The system automatically falls back to simulation mode when:
- Real services are unavailable
- OpenAI rate limits are exceeded
- Parsing errors occur
- Network connectivity issues arise

## Performance Baseline

### Pre-v4.0 Performance (Jan v3.x)
- **Overall Pass Rate**: ~50%
- **Primary Bottlenecks**: Urgency assessment (~50%), Amount detection (~50%)
- **Strengths Maintained**: Name extraction (â‰¥90%), Category detection (â‰¥90%)
- **Architecture**: Simple rule-based extraction

### Post-v4.0 Target Performance  
- **Overall Pass Rate**: 85%+ (weighted scoring)
- **Urgency Assessment**: 80%+ (up from 50%)
- **Amount Detection**: 80%+ (up from 50%)
- **Cross-Field Consistency**: 90%+ coordination success
- **Fragment Handling**: 75%+ success on noisy speech

### Key Performance Improvements
1. **6-Layer Urgency Detection**: Captures implicit urgency cues missed by keyword matching
2. **Multi-Pass Amount Extraction**: Handles vague expressions and contextual calculations
3. **Cross-Field Validation**: Prevents cascading failures from single-field errors
4. **Speech Quality Processing**: Robust handling of real-world speech patterns

## Troubleshooting

### Common Issues

#### Evaluation Mode Configuration
```bash
# Issue: Real services failing
# Solution: Use simulation mode
EVAL_MODE=simulation node run_parsing_eval.js

# Issue: OpenAI calls detected
# Solution: Enable zero-OpenAI mode
ZERO_OPENAI_MODE=true EVAL_MODE=real node run_parsing_eval.js
```

#### Dataset Loading
```bash
# Issue: Dataset not found
# Solution: Verify file path and name
ls -la backend/eval/datasets/transcripts_golden_v4_core30.jsonl

# Issue: JSON parsing errors
# Solution: Validate JSONL format
cat backend/eval/datasets/transcripts_golden_v4_core30.jsonl | jq empty
```

#### Performance Issues
```bash
# Issue: Low pass rates
# Solution: Check individual engine performance
EVAL_SCORING=binary node run_parsing_eval.js

# Issue: High execution times  
# Solution: Enable performance profiling
NODE_ENV=development node run_parsing_eval.js
```

### Debug Configuration
```typescript
// Enable detailed logging
process.env.DEBUG = 'parsing:*';

// Export trace data
process.env.TRACE_EXPORT = 'true';

// Performance monitoring
process.env.PERFORMANCE_MONITORING = 'enabled';
```

## Future Enhancements

### Phase 9 (Future): Real-Time Optimization
- Dynamic threshold adjustment based on performance feedback
- A/B testing framework for engine parameter tuning
- Real-time confidence calibration

### Phase 10 (Future): Advanced ML Integration  
- Hybrid rule-based + ML approaches (maintaining deterministic base)
- Custom embedding models for semantic similarity
- Advanced NLP preprocessing

### Phase 11 (Future): Production Analytics
- Real-time dashboard for parsing performance
- Automated alerting for performance degradation
- Historical trend analysis and optimization recommendations

---

## Support and Maintenance

For questions about the Jan v4.0 parsing system, please refer to:
- This documentation for architecture and usage
- Individual engine files for implementation details  
- Evaluation outputs for performance analysis
- Test cases in the dataset for expected behavior examples

**System Status**: âœ… **Production Ready** - All phases completed, comprehensive testing suite available, deterministic evaluation capabilities established.